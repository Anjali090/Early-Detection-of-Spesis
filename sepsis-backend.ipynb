{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "from collections import Counter\n",
    "import io\n",
    "#from google.colab import files   \n",
    "#uploaded = files.upload()\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[265]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# In[152]:\n",
    "\n",
    "def train_model():\n",
    "\n",
    "    data = pd.read_csv('sepsis.csv')\n",
    "\n",
    "    # In[153]:\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    imputer = SimpleImputer(strategy=\"median\")\n",
    "    imputer.fit(data)\n",
    "    x= imputer.transform(data)\n",
    "\n",
    "    # In[154]:\n",
    "\n",
    "\n",
    "    #from sklearn import preprocessing\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(data)\n",
    "    data = pd.DataFrame(scaler.transform(data), index=data.index, columns=data.columns)\n",
    "\n",
    "\n",
    "    # In[171]:\n",
    "\n",
    "\n",
    "    x = data.loc[:, data.columns!= 'SepsisLabel']\n",
    "    y = data.loc[:, data.columns == 'SepsisLabel']\n",
    "    #type(x)\n",
    "\n",
    "\n",
    "    # In[221]:\n",
    "\n",
    "\n",
    "    #from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=20)\n",
    "\n",
    "    x_pca = pca.fit_transform(x)\n",
    "    #scores=pd.DataFrame(x_pca)\n",
    "    #print(scores)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    #print(pd.DataFrame(pca.components_,columns=x.columns))\n",
    "    #explained_variance\n",
    "    #s=pca.components_\n",
    "    #s.shape\n",
    "    #x_pca.shape\n",
    "\n",
    "\n",
    "\n",
    "    # In[175]:\n",
    "\n",
    "\n",
    "    #from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_pca,y,test_size=0.25, random_state = 62)\n",
    "\n",
    "\n",
    "    # In[177]:\n",
    "\n",
    "\n",
    "    #!pip install -U imbalanced-learn\n",
    "    #import imblearn\n",
    "    #from imblearn.over_sampling import SMOTE\n",
    "\n",
    "\n",
    "    # In[273]:\n",
    "\n",
    "\n",
    "    #%%time\n",
    "    kf = StratifiedKFold(n_splits=4, random_state=62)\n",
    "    cross_val_f1_score_lst = []\n",
    "    cross_val_accuracy_lst = []\n",
    "    cross_val_recall_lst = []\n",
    "    cross_val_precision_lst = []\n",
    "\n",
    "\n",
    "    for train_index_ls, validation_index_ls in kf.split(X_train, y_train):\n",
    "        # keeping validation set apart and oversampling in each iteration using smote \n",
    "        train, validation = X_train[train_index_ls], X_train[validation_index_ls]\n",
    "        target_train, target_val = y_train.iloc[train_index_ls], y_train.iloc[validation_index_ls]\n",
    "        sm = SMOTE(random_state=62)\n",
    "        X_train_res, y_train_res = sm.fit_sample(train, target_train)\n",
    "        #print (X_train_res.shape, y_train_res.shape)\n",
    "        \n",
    "       #ExtraTreeClassifier\n",
    "        #from sklearn.ensemble import ExtraTreesClassifier\n",
    "        etc = ExtraTreesClassifier( n_estimators=1000, criterion=\"entropy\", max_features=\"auto\", min_samples_leaf=1, min_samples_split=5)\n",
    "        \n",
    "        # fit the model on the whole dataset\n",
    "        etc.fit(X_train_res, y_train_res)\n",
    "        \n",
    "        #predict on the train data\n",
    "        etc_predict = etc.predict(validation)\n",
    "        \n",
    "        '''\n",
    "        from sklearn.metrics import accuracy_score,f1_score,recall_score, precision_score,confusion_matrix\n",
    "        cross_val_recall_lst.append(recall_score(target_val, etc_predict))\n",
    "        cross_val_accuracy_lst.append(accuracy_score(target_val, etc_predict))\n",
    "        cross_val_precision_lst.append(precision_score(target_val, etc_predict))\n",
    "        cross_val_f1_score_lst.append(f1_score(target_val, etc_predict))\n",
    "    print ('Cross validated accuracy: {}'.format(np.mean(cross_val_accuracy_lst)))\n",
    "    print ('Cross validated recall score: {}'.format(np.mean(cross_val_recall_lst)))\n",
    "    print ('Cross validated precision score: {}'.format(np.mean(cross_val_precision_lst)))\n",
    "    print ('Cross validated f1_score: {}'.format(np.mean(cross_val_f1_score_lst)))\n",
    "    '''\n",
    "\n",
    "\n",
    "    # In[248]:\n",
    "\n",
    "\n",
    "\n",
    "    #predict on the test data\n",
    "    etc_predict_test = etc.predict(X_test)\n",
    "    #print(X_test)\n",
    "    #print(etc_predict_test)\n",
    "    #print(type(X_test))\n",
    "    #print(len(X_test))\n",
    "\n",
    "    '''\n",
    "    from sklearn.metrics import accuracy_score,f1_score,recall_score, precision_score,confusion_matrix\n",
    "    print(\"accuracy:\",accuracy_score(etc_predict_test,y_test))\n",
    "    print(\"recall score:\",recall_score(etc_predict_test,y_test))\n",
    "    print(\"precision score: \", precision_score(etc_predict_test,y_test))\n",
    "    print(\"f1 score: \", f1_score(etc_predict_test,y_test))\n",
    "    print('train-set confusion matrix:\\n', confusion_matrix(etc_predict_test,y_test))\n",
    "    etc_list=[accuracy_score(etc_predict_test,y_test),recall_score(etc_predict_test,y_test),precision_score(etc_predict_test,y_test),f1_score(etc_predict_test,y_test)]\n",
    "    print(etc_list)\n",
    "    '''\n",
    "\n",
    "    return pca,etc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"module 2.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1APfAIISuA27ITPKEi1QtidTc3S56f5_C\n",
    "\"\"\"\n",
    "\n",
    "# SIRS score function \n",
    "\n",
    "def sirs_score(temp, hr, rr, wbc):\n",
    "  dict = {}\n",
    "  sirs = 0\n",
    "  if(temp>38):\n",
    "    sirs=sirs+1\n",
    "    dict['temp'] = 'high'\n",
    "  elif(temp<36):\n",
    "    dict['temp'] = 'low'\n",
    "    sirs=sirs+1\n",
    "  else:\n",
    "    dict['temp'] = 'normal'\n",
    "  \n",
    "  if(hr>90):\n",
    "    dict['hr'] = 'high'\n",
    "    sirs=sirs+1\n",
    "  else:\n",
    "    dict['hr'] = 'normal'\n",
    "\n",
    "  if(rr>20):\n",
    "    dict['rr'] = 'high'\n",
    "    sirs=sirs+1\n",
    "  else:\n",
    "    dict['rr'] = 'normal'\n",
    "\n",
    "  if(wbc>12):\n",
    "    sirs=sirs+1\n",
    "    dict['wbc'] = 'high'\n",
    "  elif(wbc<4):\n",
    "    dict['wbc'] = 'low'\n",
    "    sirs=sirs+1\n",
    "  else:\n",
    "    dict['wbc'] = 'normal'\n",
    "\n",
    "  return sirs,dict\n",
    "\n",
    "##sample input\n",
    "##sirs_score(36.11,108,29,5.7)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"module3.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1atRFuOoVaGKCGznKtHFU-MvonjmVxe1n\n",
    "\"\"\"\n",
    "\n",
    "# Module 3 - medical recomendation\n",
    "\n",
    "def medical_rec(sympt):\n",
    "    rec={}\n",
    "    hr_high=[\"Diuretics\", \"Beta-blockers\", \"ACE inhibitors\", \"Vasodilators\", \"Angiotensin II receptor blockers\"]\n",
    "    temp_high=[\"Acetaminophen\", \"Ibuprofen\", \"Aspirin\"]\n",
    "    wbc_high=[\"Antibiotics\", \"Anticonvulsants\", \"Antithyroid drugs\",\"Arsenicals\",\"Captopril\",\"Chlorpromazine\",\"Clozapine\"]\n",
    "    wbc_low=[\"Beta-adrenergic agonist\",\"Corticosteroids\",\"Epinephrine\",\"Granulocyte colony-stimulating factor\",\"Heparin\",\"Lithium\"]\n",
    "    rr_high=[\"alprazolam\", \"clonazepam\", \"buspirone\"]\n",
    "\n",
    "    if(sympt['temp']=='high'):\n",
    "        rec['high_temp']=temp_high\n",
    "    \n",
    "    if(sympt['rr']=='high'):\n",
    "        rec['high_rr']=rr_high;\n",
    "    \n",
    "    if(sympt['hr']=='high'):\n",
    "        rec['high_hr']=hr_high\n",
    "    \n",
    "    if(sympt['wbc']=='low'):\n",
    "        rec['low_wbc']= wbc_low;\n",
    "    elif(sympt['wbc']=='high'):\n",
    "      rec['high_wbc']= wbc_high\n",
    "\n",
    "    return rec;\n",
    "\n",
    "#sample input\n",
    "##medical_rec({'hr': 'high', 'rr': 'high', 'temp': 'normal', 'wbc': 'normal'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def query_input(pca,etc):\n",
    "\n",
    "    attribute_list=['HR', 'O2Sat', 'Temp', 'SBP', 'MAP', 'DBP', 'Resp', 'EtCO2',\n",
    "           'BaseExcess', 'HCO3', 'FiO2', 'pH', 'PaCO2', 'SaO2', 'AST', 'BUN',\n",
    "           'Alkalinephos', 'Calcium', 'Chloride', 'Creatinine', 'Bilirubin_direct',\n",
    "           'Glucose', 'Lactate', 'Magnesium', 'Phosphate', 'Potassium',\n",
    "           'Bilirubin_total', 'TroponinI', 'Hct', 'Hgb', 'PTT', 'WBC',\n",
    "           'Fibrinogen', 'Platelets', 'Age', 'Gender', 'Unit1', 'Unit2',\n",
    "           'HospAdmTime', 'ICULOS']\n",
    "\n",
    "    # In[243]:\n",
    "\n",
    "    attribute_dict = dict.fromkeys(attribute_list , 0)\n",
    "\n",
    "    attribute_dict['HR']=119\n",
    "    attribute_dict['O2Sat']=100\n",
    "    attribute_dict['Temp']=37.94\n",
    "    attribute_dict['SBP']=140\n",
    "    attribute_dict['MAP']=106\n",
    "    attribute_dict['DBP']=85\n",
    "    attribute_dict['Resp']=26.5\n",
    "    attribute_dict['FiO2']=0.35\n",
    "    attribute_dict['pH']=0\n",
    "    attribute_dict['SaO2']=0\n",
    "    attribute_dict['BUN']=0\n",
    "    attribute_dict['Calcium']=0\n",
    "    attribute_dict['Chloride']=0\n",
    "    attribute_dict['Glucose']=0\n",
    "    attribute_dict['Hgb']=0\n",
    "    attribute_dict['WBC']=189\n",
    "    attribute_dict['Age']=27.92\n",
    "    attribute_dict['Gender']=1\n",
    "    attribute_dict['Unit1']=0\n",
    "    attribute_dict['Unit2']=0\n",
    "    attribute_dict['HospAdmTime']=-0.03\n",
    "    attribute_dict['ICULOS']=249\n",
    "    #attribute_dict\n",
    "\n",
    "    # In[264]:\n",
    "\n",
    "\n",
    "    #from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    user_input=pd.DataFrame.from_dict(attribute_dict,orient='index')      #<class 'pandas.core.frame.DataFrame'>\n",
    "    #print(type(user_input)) #dataframe\n",
    "\n",
    "    scalar = preprocessing.MinMaxScaler()\n",
    "    scaled_data=scalar.fit_transform(user_input)             #<class 'numpy.ndarray'>\n",
    "    #print(scaled_data)\n",
    "    #print(type(scaled_data))#numpyarray\n",
    "\n",
    "    temp = pd.DataFrame(scaled_data,index=user_input.index,columns=user_input.columns)\n",
    "    input_data=temp.transpose()                               #<class 'pandas.core.frame.DataFrame'>\n",
    "    #print(input_data)\n",
    "    #print(type(input_data)) #dataframe\n",
    "    red_data_pca=pca.transform(input_data)                      #<class 'numpy.ndarray'>\n",
    "    #print(type(red_data_pca)) #numpy array\n",
    "    #print(red_data_pca.shape)\n",
    "    #print(red_data_pca)\n",
    "   \n",
    "    New_predict = etc.predict(red_data_pca)\n",
    "\n",
    "    print(int(New_predict[0]))\n",
    "\n",
    "\n",
    "    if(int(New_predict[0])):\n",
    "        score,dictionary=sirs_score(attribute_dict['Temp'], attribute_dict['HR'], attribute_dict['Resp'], attribute_dict['WBC'])\n",
    "        if(score<=2):\n",
    "            print(\"Sepsis Stage 1\")\n",
    "        if(score==3):\n",
    "            print(\"Sepsis Stage 2\")\n",
    "        if(score==4):\n",
    "            print(\"Sepsis Stage 3\")\n",
    "        medication_dict=medical_rec(dictionary)\n",
    "        print(\"Medical recommendation\")\n",
    "        print(medication_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda33\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "<ipython-input-2-ccb3dbe927a7>:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  etc.fit(X_train_res, y_train_res)\n",
      "<ipython-input-2-ccb3dbe927a7>:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  etc.fit(X_train_res, y_train_res)\n",
      "<ipython-input-2-ccb3dbe927a7>:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  etc.fit(X_train_res, y_train_res)\n",
      "<ipython-input-2-ccb3dbe927a7>:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  etc.fit(X_train_res, y_train_res)\n"
     ]
    }
   ],
   "source": [
    "pca_var,etc_var=train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "query_input(pca_var,etc_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
